{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from utils import *\n",
    "import time\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_cfg     = \"../yoloface/cfg/yolov3-face.cfg\"\n",
    "# model_weights = \"../yoloface/model-weights/yolov3-wider_16000.weights\"\n",
    "# net = cv2.dnn.readNetFromDarknet(model_cfg, model_weights)\n",
    "# net = cv2.dnn.readNetFromTensorflow('saved_model/saved_model.pb', 'saved_model/model.pbtext')\n",
    "# net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "# net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying image...\n",
      "[[0.25408763 0.7459124 ]]\n",
      "inference :  0.094 s\n",
      "classifying image...\n",
      "[[0.37965643 0.62034357]]\n",
      "inference :  0.003 s\n",
      "classifying image...\n",
      "[[0.3300987 0.6699013]]\n",
      "inference :  0.003 s\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "target_x = 550\n",
    "target_y = 150\n",
    "target_w = 256\n",
    "target_h = 256\n",
    "\n",
    "while True:\n",
    "    ret, im = cap.read()\n",
    "    cv2.rectangle(im, (target_x,target_y), (target_x+target_w, target_y+target_h), (255, 0, 0), 2)\n",
    "    # %matplotlib inline\n",
    "    img = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    # plt.imshow(img)\n",
    "    # blur = cv2.GaussianBlur(im, (0, 0), 1)\n",
    "    cv2.imshow('camera capture', im) #blur)\n",
    "    key = cv2.waitKey(100)\n",
    "    \n",
    "    if key == 27 or key == ord('q'): # Esc or q\n",
    "        break\n",
    "    elif key == ord('c'):\n",
    "      print('classifying image...')\n",
    "      t2 = time.perf_counter()\n",
    "      # image = img[: ,w_offset:w_offset + ORG_HEIGHT, :]\n",
    "      image = cv2.resize(im[target_y:target_y+target_h, target_x:target_x+target_w], (32, 32)) # , interpolation = cv2.INTER_)\n",
    "      x = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "      # array_to_img(x).save('classified.jpg')\n",
    "      x = np.expand_dims(x, axis=0)\n",
    "      x = preprocess_input(x)\n",
    "      preds = model.predict(x)\n",
    "      # print('Predicted:', decode_predictions(preds))      \n",
    "      print(preds)\n",
    "      t3 = time.perf_counter() # clock()\n",
    "      print('inference :  %.3f s' % (t3 - t2))\n",
    "      # break\n",
    "# 一旦画像削除の命令\n",
    "cap.release()\n",
    "# カメラが立ち上がっているので、全てのウィンドウを閉じる\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 0\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 2\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n",
      "[i] ==> # detected faces: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dccf94fe191b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Runs the forward pass to get output of the output layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_outputs_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Remove the bounding boxes with low confidence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cascade_path = \"../opencv_test/haarcascade_frontalface_alt.xml\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "target_x = 550\n",
    "target_y = 150\n",
    "target_w = 256\n",
    "target_h = 256\n",
    "\n",
    "while True:\n",
    "    ret, im = cap.read()\n",
    "    cv2.rectangle(im, (target_x,target_y), (target_x+target_w, target_y+target_h), (255, 0, 0), 2)\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(im[target_y:target_y+target_h, target_x:target_x+target_w], 1 / 255, (IMG_WIDTH, IMG_HEIGHT),\n",
    "                                [0, 0, 0], 1, crop=False)\n",
    "    # Sets the input to the network\n",
    "    net.setInput(blob)\n",
    "    # Runs the forward pass to get output of the output layers\n",
    "    outs = net.forward(get_outputs_names(net))\n",
    "\n",
    "    # Remove the bounding boxes with low confidence\n",
    "    faces = post_process(im, outs, CONF_THRESHOLD, NMS_THRESHOLD)\n",
    "    print('[i] ==> # detected faces: {}'.format(len(faces)))\n",
    "    # ここからのコードを変えながら、微調整するとオリジナルになると思います。\n",
    "    # img_gray = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "    # cascade = cv2.CascadeClassifier(cascade_path)\n",
    "    # faces = cascade.detectMultiScale(img_gray, scaleFactor=1.1, minNeighbors=2, minSize=(80, 80)) # minNeighborsは人数\n",
    "\n",
    "    # if len(faces) > 0:\n",
    "    #    print(faces)\n",
    "    #    for (x, y, w, h) in faces:\n",
    "    #        cv2.rectangle(im, (x,y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    # %matplotlib inline\n",
    "    img = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    # plt.imshow(img)\n",
    "    # blur = cv2.GaussianBlur(im, (0, 0), 1)\n",
    "    cv2.imshow('camera capture', im) #blur)\n",
    "    key = cv2.waitKey(100)\n",
    "    \n",
    "    if key == 27 or key == ord('q'): # Esc or q\n",
    "        break\n",
    "# 一旦画像削除の命令\n",
    "cap.release()\n",
    "# カメラが立ち上がっているので、全てのウィンドウを閉じる\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
